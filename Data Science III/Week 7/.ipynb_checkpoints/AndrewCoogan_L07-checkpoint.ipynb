{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Author -- Andrew Coogan\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius_mu</th>\n",
       "      <th>Radius_se</th>\n",
       "      <th>Radius_max</th>\n",
       "      <th>Texture_mu</th>\n",
       "      <th>Texture_se</th>\n",
       "      <th>Texture_max</th>\n",
       "      <th>Perimeter_mu</th>\n",
       "      <th>Perimeter_se</th>\n",
       "      <th>Perimeter_se</th>\n",
       "      <th>...</th>\n",
       "      <th>Concavity_max</th>\n",
       "      <th>Concave_mu</th>\n",
       "      <th>Concave_se</th>\n",
       "      <th>Concave_max</th>\n",
       "      <th>Symmetry_mu</th>\n",
       "      <th>Symmetry_se</th>\n",
       "      <th>Symmetry_max</th>\n",
       "      <th>Fractal_mu</th>\n",
       "      <th>Fractal_se</th>\n",
       "      <th>Fractal_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Diagnosis  Radius_mu  Radius_se  Radius_max  Texture_mu  Texture_se  \\\n",
       "ID                                                                              \n",
       "842302            1      17.99      10.38      122.80      1001.0     0.11840   \n",
       "842517            1      20.57      17.77      132.90      1326.0     0.08474   \n",
       "84300903          1      19.69      21.25      130.00      1203.0     0.10960   \n",
       "84348301          1      11.42      20.38       77.58       386.1     0.14250   \n",
       "84358402          1      20.29      14.34      135.10      1297.0     0.10030   \n",
       "\n",
       "          Texture_max  Perimeter_mu  Perimeter_se  Perimeter_se     ...       \\\n",
       "ID                                                                  ...        \n",
       "842302        0.27760        0.3001       0.14710        0.2419     ...        \n",
       "842517        0.07864        0.0869       0.07017        0.1812     ...        \n",
       "84300903      0.15990        0.1974       0.12790        0.2069     ...        \n",
       "84348301      0.28390        0.2414       0.10520        0.2597     ...        \n",
       "84358402      0.13280        0.1980       0.10430        0.1809     ...        \n",
       "\n",
       "          Concavity_max  Concave_mu  Concave_se  Concave_max  Symmetry_mu  \\\n",
       "ID                                                                          \n",
       "842302            25.38       17.33      184.60       2019.0       0.1622   \n",
       "842517            24.99       23.41      158.80       1956.0       0.1238   \n",
       "84300903          23.57       25.53      152.50       1709.0       0.1444   \n",
       "84348301          14.91       26.50       98.87        567.7       0.2098   \n",
       "84358402          22.54       16.67      152.20       1575.0       0.1374   \n",
       "\n",
       "          Symmetry_se  Symmetry_max  Fractal_mu  Fractal_se  Fractal_max  \n",
       "ID                                                                        \n",
       "842302         0.6656        0.7119      0.2654      0.4601      0.11890  \n",
       "842517         0.1866        0.2416      0.1860      0.2750      0.08902  \n",
       "84300903       0.4245        0.4504      0.2430      0.3613      0.08758  \n",
       "84348301       0.8663        0.6869      0.2575      0.6638      0.17300  \n",
       "84358402       0.2050        0.4000      0.1625      0.2364      0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = 'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'\n",
    "cols = ['ID', 'Diagnosis', \\\n",
    "        'Radius_mu', 'Radius_se', 'Radius_max', \n",
    "        'Texture_mu', 'Texture_se', 'Texture_max', \\\n",
    "        'Perimeter_mu','Perimeter_se','Perimeter_se', \\\n",
    "        'Area_mu', 'Area_se', 'Area_max', \\\n",
    "        'Smoothness_mu', 'Smoothness_se', 'Smoothness_max', \\\n",
    "        'Compactness_mu', 'Compactness_se', 'Compactness_max', \\\n",
    "        'Concavity_mu', 'Concavity_se','Concavity_max', \\\n",
    "        'Concave_mu', 'Concave_se', 'Concave_max', \\\n",
    "        'Symmetry_mu', 'Symmetry_se', 'Symmetry_max', \\\n",
    "        'Fractal_mu', 'Fractal_se', 'Fractal_max']\n",
    "data = pd.read_csv(link, header=None)\n",
    "data.columns = cols\n",
    "data.set_index('ID', inplace = True)\n",
    "data.replace({'M' : 1, 'B' : 0}, inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = copy.deepcopy(data.Diagnosis)\n",
    "data.drop('Diagnosis', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(\n",
    "    data, \n",
    "    target,\n",
    "    random_state = 42,\n",
    "    test_size = 0.2,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Smoothness_se', 'Concavity_max', 'Concave_mu', 'Concave_se',\n",
       "       'Symmetry_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 0.01\n",
    "clf_1 = linear_model.Lasso(alpha = l)\n",
    "clf_1.fit(feature_train, target_train)\n",
    "\n",
    "columns_used = data.columns[clf_1.coef_ > 0]\n",
    "columns_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of square of coefficients = 0.0130338415\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of square of coefficients = %.10f\"%np.sum(clf_1.coef_**2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Testing Data for .5 Threshold = 94.7368%\n",
      "Precision on Testing Data for .5 Threshold = 93.4818%\n",
      "Recall on Testing Data for .5 Threshold = 95.3846%\n",
      "F1 on Testing Data for .5 Threshold = 94.7931%\n"
     ]
    }
   ],
   "source": [
    "target_pred_1 = clf_1.predict(feature_test)\n",
    "\n",
    "tp_1_MASTER = copy.deepcopy(target_pred_1)\n",
    "\n",
    "target_pred_1[target_pred_1 > 0.5] = 1\n",
    "target_pred_1[target_pred_1 <= 0.5] = 0\n",
    "\n",
    "acc = accuracy_score(target_pred_1, target_test)\n",
    "prec = precision_score(target_pred_1, target_test, average = 'macro')\n",
    "rec= recall_score(target_pred_1, target_test, average = 'macro')\n",
    "F1 = f1_score(target_pred_1, target_test, average = 'weighted')\n",
    "\n",
    "print(\"Accuracy on Testing Data for .5 Threshold = %.4f%%\"%(100 * acc))\n",
    "print(\"Precision on Testing Data for .5 Threshold = %.4f%%\"%(100 * prec))\n",
    "print(\"Recall on Testing Data for .5 Threshold = %.4f%%\"%(100 * rec))\n",
    "print(\"F1 on Testing Data for .5 Threshold = %.4f%%\"%(100 * F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Concave_mu', 'Concave_se'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 0.5\n",
    "clf_2 = linear_model.Lasso(alpha = l)\n",
    "clf_2.fit(data, target)\n",
    "\n",
    "columns_used = data.columns[clf_2.coef_ > 0]\n",
    "columns_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of square of coefficients = 0.0001524318\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of square of coefficients = %.10f\"%np.sum(clf_2.coef_**2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Testing Data for .5 Threshold = 93.8596%\n",
      "Precision on Testing Data for .5 Threshold = 91.8605%\n",
      "Recall on Testing Data for .5 Threshold = 95.5128%\n",
      "F1 on Testing Data for .5 Threshold = 93.9875%\n"
     ]
    }
   ],
   "source": [
    "target_pred_2 = clf_2.predict(feature_test)\n",
    "\n",
    "tp_2_MASTER = copy.deepcopy(target_pred_2)\n",
    "\n",
    "target_pred_2[target_pred_2 > 0.5] = 1\n",
    "target_pred_2[target_pred_2 <= 0.5] = 0\n",
    "\n",
    "acc = accuracy_score(target_pred_2, target_test)\n",
    "prec = precision_score(target_pred_2, target_test, average = 'macro')\n",
    "rec= recall_score(target_pred_2, target_test, average = 'macro')\n",
    "F1 = f1_score(target_pred_2, target_test, average = 'weighted')\n",
    "\n",
    "print(\"Accuracy on Testing Data for .5 Threshold = %.4f%%\"%(100 * acc))\n",
    "print(\"Precision on Testing Data for .5 Threshold = %.4f%%\"%(100 * prec))\n",
    "print(\"Recall on Testing Data for .5 Threshold = %.4f%%\"%(100 * rec))\n",
    "print(\"F1 on Testing Data for .5 Threshold = %.4f%%\"%(100 * F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, the lower the alpha value the more variables we are going to have as there is less of a penalty for introducing new parameters.  So the simplist model above is the one that sets the alpha parameter at 0.5.\n",
    "\n",
    "As a slight reminder for me and to better demonstrate what is going on here:\n",
    "\n",
    "accuracy = (true positives + true negatives) / # of samples\n",
    "\n",
    "precision = true positives / (true positives + false positives)\n",
    "\n",
    "recall = true positives / (true positives + false negatives)\n",
    "\n",
    "F1 = (2 * precision * recall ) / (precision + recall)\n",
    "\n",
    "What we are doing here is diagnosing tumors.  Misclassifying a patient as a false positive or false negative has its own repercussions.  I believe that a false negative is the worst case scenario.  With that said I would postulate that recall is the best metric to determine this.  Using this as the sole criteria, I believe the simpler model is better because it has a higher reall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statement(real, pred_t, fp_cost, fn_cost, threshold):\n",
    "    pred = copy.deepcopy(pred_t)\n",
    "    pred[pred > threshold] = 1\n",
    "    pred[pred <= threshold] = 0\n",
    "    tn, fp, fn, tp = confusion_matrix(real, pred).ravel()\n",
    "    recall = 100 * tp / (tp + fn)\n",
    "    cost = (fp_cost * fp) + (fn_cost * fn)\n",
    "    print(\"Using alpha score of %.2f, we get a reall of %.4f%%, at a cost of $%.2f}\"%\n",
    "          (threshold, recall, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the alpha score of 0.01 for the LASSO regression:\n",
      "Using alpha score of 0.30, we get a reall of 100.0000%, at a cost of $140000.00}\n",
      "Using alpha score of 0.50, we get a reall of 88.3721%, at a cost of $510000.00}\n",
      "Using alpha score of 0.70, we get a reall of 67.4419%, at a cost of $1400000.00}\n"
     ]
    }
   ],
   "source": [
    "print('Using the alpha score of 0.01 for the LASSO regression:')\n",
    "print_statement(target_test, tp_1_MASTER, 10000, 100000, 0.3)\n",
    "print_statement(target_test, tp_1_MASTER, 10000, 100000, 0.5)\n",
    "print_statement(target_test, tp_1_MASTER, 10000, 100000, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the alpha score of 0.50 for the LASSO regression:\n",
      "Using alpha score of 0.30, we get a reall of 97.6744%, at a cost of $190000.00}\n",
      "Using alpha score of 0.50, we get a reall of 83.7209%, at a cost of $700000.00}\n",
      "Using alpha score of 0.70, we get a reall of 51.1628%, at a cost of $2100000.00}\n"
     ]
    }
   ],
   "source": [
    "print('Using the alpha score of 0.50 for the LASSO regression:')\n",
    "print_statement(target_test, tp_2_MASTER, 10000, 100000, 0.3)\n",
    "print_statement(target_test, tp_2_MASTER, 10000, 100000, 0.5)\n",
    "print_statement(target_test, tp_2_MASTER, 10000, 100000, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above six iterations, we can see that the more complex model (alpha of 0.01) and using a score cut of of 0.3 (meaning it needs to be only score a 0.3 in the model or more) gives us no false neatives, meaning there is a 100% recall score.  This proves to give the cheapest outcome, but almost 10% of the samples are false positives.  Its a very conservative model, but the fact that a false negaive is 10x the cost of a false positive, it will always take nine false positives before it takes a false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
